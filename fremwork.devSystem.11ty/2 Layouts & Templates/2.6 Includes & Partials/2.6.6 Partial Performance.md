| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **2.6.6 Partial Performance** | Efficiency | File I/O overhead; Caching; Render Trees | Includes aren't free. |
| **[[2.6.6.1 The I/O Cost]]** | Overhead | Every `{% include %}` touches the disk; 10,000 files x 10 includes = 100k reads | Disk access adds up. |
| **[[2.6.6.2 Engine Caching]]** | Mitigation | Nunjucks/Liquid cache compiled templates; First read is slow, second is fast | The engine remembers. |
| **[[2.6.6.3 Circular Dependencies]]** | Crash | A includes B includes A; Stack Overflow errors | Loops kill the build. |
| **[[2.6.6.4 Debugging Slow Builds]]** | Profiling | `DEBUG=Eleventy*` to see slow template rendering times | Find the bottleneck. |
| **[[2.6.6.5 Inline vs Include]]** | Tradeoff | Small, highly repetitive loops (like lists) might benefit from inlining | Copy-paste is faster than read. |

# 2.6.6 Partial Performance

When you break your site into atomic components, you gain maintainability but pay a small performance tax. Every `{% include %}` requires the engine to:
1.  Resolve the path.
2.  Read the file from disk.
3.  Parse/Compile the template string.
4.  Render it with the current context.

For a site with 10 pages, this is irrelevant. For a site with 10,000 pages, it matters.

---

## 2.6.6.1 The I/O Cost

If you have a loop of 1000 items, and inside the loop is an include:

```html
{% for item in bigList %}
  {% include "card.njk" %}
{% endfor %}
```

Conceptually, you are asking for `card.njk` 1000 times. Even with SSDs, file system calls are expensive compared to CPU operations.

---

## 2.6.6.2 Engine Caching

Fortunately, modern template engines (Nunjucks and Liquid) rely heavily on **Caching**.

1.  **First Call**: Read from disk -> Compile to Function -> Store in Memory -> Execute.
2.  **Subsequent Calls**: Retrieve Function from Memory -> Execute.

So, the loop above doesn't actually hit the disk 1000 times; it hits it once. The overhead becomes purely about function execution context switching (creating a new scope for the include), which is very fast in V8 (Node.js).

---

## 2.6.6.3 Circular Dependencies

The biggest danger with extensive include trees is circular logic.

*   `parent.njk` includes `child.njk`.
*   `child.njk` includes `parent.njk`.

This creates an infinite recursion that will crash the Node.js process with a "Maximum stack size exceeded" error. This often happens when building complex recursive navigation menus.

**Fix**: Pass a flag to prevent re-inclusion or restructure the component to be flatter.

---

## 2.6.6.4 Debugging Slow Builds

If your build feels slow, you can profile it.

**Command**:
```bash
DEBUG=Eleventy:Benchmark* npx @11ty/eleventy
```

This will output timing metrics for various parts of the build. If you see specific templates taking disproportionately long, checks for:
1.  Heavy logic/math inside the template.
2.  Network requests (fetch) happening inside data files relevant to that template.
3.  Excessive numbers of shortcode/include calls.

---

## 2.6.6.5 Inline vs Include (Micro-Optimization)

In extreme cases (e.g., rendering a table with 50,000 rows), defining the row HTML inside the main file (Inlining) is faster than including a `row.njk` file.

**Slow (Clean)**:
```html
{% for row in rows %}
  {% include "row.njk" %}
{% endfor %}
```

**Fast (Messy)**:
```html
{% for row in rows %}
  <tr><td>{{ row.data }}</td></tr>
{% endfor %}
```

Only optimization for this if you have measured a problem. **Premature optimization is the root of all evil.**

---

## Quick Reference

| Factor | Impact | Note |
| :--- | :--- | :--- |
| **Disk Read** | Low (Cached) | Only first read is slow. |
| **Context Switch** | Medium | Creating new scopes for includes costs CPU. |
| **Recursion** | Fatal | Infinite loops crash the build. |
| **Optimization** | Last Resort | Only inline code if profiling proves slowness. |
